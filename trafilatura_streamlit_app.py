import json
import re
import streamlit as st
import trafilatura
import requests
from requests.exceptions import RequestException

st.set_page_config(page_title="Trafilatura Content Extractor", layout="wide")

st.title("üîó Extrator de T√≠tulo e Texto via Trafilatura")
st.markdown(
    "Cole a URL de qualquer p√°gina p√∫blica. O app far√° o download, limpar√° o HTML e mostrar√° **T√≠tulo** e **Texto** prontos para copiar."
)

# ----------------------------
# Network helpers
# ----------------------------

def fetch_url_raw(url: str) -> str | None:
    """Realiza o download bruto do HTML.

    1. Tenta `trafilatura.fetch_url` (r√°pido, j√° segue redirects)
    2. Se falhar, faz `requests.get` com User‚ÄëAgent de desktop
    """
    html = trafilatura.fetch_url(url)
    if html:
        return html

    try:
        resp = requests.get(
            url,
            headers={
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/124.0.0.0 Safari/537.36"
                )
            },
            timeout=20,
        )
        if resp.ok:
            resp.encoding = resp.apparent_encoding
            return resp.text
    except RequestException:
        pass
    return None


def maybe_amp_url(url: str) -> str:
    """Tenta construir a vers√£o /amp de uma URL."""
    if url.rstrip("/").endswith("/amp"):
        return url
    return url.rstrip("/") + "/amp"

# ----------------------------
# Next.js specific helper
# ----------------------------

def extract_from_next_data(html: str) -> str | None:
    """Extrai o corpo do artigo a partir do script JSON `__NEXT_DATA__`.

    ‚Ä¢ Captura todos os blocos `__NEXT_DATA__` (pode haver mais de um).
    ‚Ä¢ Itera de tr√°s para frente: o √∫ltimo costuma conter o payload completo.
    ‚Ä¢ Procura os caminhos `props.pageProps.post.content` ou
      `props.pageProps.data.post.content`.
    """
    scripts = re.findall(r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*>(.*?)</script>', html, re.DOTALL)
    if not scripts:
        return None

    for raw_json in reversed(scripts):
        try:
            data = json.loads(raw_json)
        except Exception:
            continue

        page_props = data.get("props", {}).get("pageProps", {})
        post_obj = page_props.get("post") or page_props.get("data", {}).get("post")
        if not post_obj or not isinstance(post_obj, dict):
            continue

        content_html = post_obj.get("content")
        if content_html and isinstance(content_html, str):
            txt = trafilatura.html2txt(content_html)
            if txt and len(txt.split()) > 50:
                return txt.strip()
    return None

# ----------------------------
# Extraction pipeline
# ----------------------------

def extract_text(html: str) -> str | None:
    """Executa uma cascata de t√©cnicas para obter texto limpo."""
    # 0) Dados Next.js
    txt = extract_from_next_data(html)
    if txt:
        return txt

    # 1) Heur√≠stica padr√£o (precis√£o)
    txt = trafilatura.extract(html, include_formatting=False, include_links=False, favor_recall=False)
    if txt and len(txt.split()) > 50:
        return txt.strip()

    # 2) Heur√≠stica recall (captura mais, por√©m com ru√≠do)
    txt = trafilatura.extract(html, include_formatting=False, include_links=False, favor_recall=True)
    if txt and len(txt.split()) > 50:
        return txt.strip()

    # 3) Readability‚Äëlxml ‚Üí html2txt
    try:
        from readability import Document
        main_html = Document(html).summary(html_partial=True)
        txt = trafilatura.html2txt(main_html)
        if txt and len(txt.split()) > 50:
            return txt.strip()
    except Exception:
        pass

    # 4) html2txt puro
    try:
        txt = trafilatura.html2txt(html)
        if txt and len(txt.split()) > 50:
            return txt.strip()
    except Exception:
        pass

    # 5) BeautifulSoup fallback
    try:
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, "html.parser")
        txt = soup.get_text("\n", strip=True)
        if txt and len(txt.split()) > 50:
            return txt
    except Exception:
        pass

    return None

# ----------------------------
# Streamlit UI
# ----------------------------

url = st.text_input("Insira a URL a ser processada:")

if url:
    with st.spinner("‚åõ Baixando e extraindo conte√∫do‚Ä¶"):
        html = fetch_url_raw(url)
        text: str | None = None
        if html:
            text = extract_text(html)

        if not text:  # tenta vers√£o AMP
            amp_html = fetch_url_raw(maybe_amp_url(url))
            if amp_html:
                text = extract_text(amp_html)
                if text:
                    html = amp_html

        if not html:
            st.error("‚ùå N√£o foi poss√≠vel baixar a p√°gina. Verifique a URL e tente novamente.")
        else:
            # ----- T√≠tulo -----
            title: str | None = None
            try:
                from trafilatura import extract_title  # type: ignore
                title = extract_title(html)
            except Exception:
                pass

            if title is None:
                try:
                    meta = trafilatura.extract_metadata(html)
                    if meta:
                        if isinstance(meta, dict):
                            title = meta.get("title")
                        else:
                            title = getattr(meta, "title", None)
                        if title is None and isinstance(meta, str):
                            title = json.loads(meta).get("title")
                except Exception:
                    pass

            title = title or "T√≠tulo n√£o encontrado"
            text = text or "Texto n√£o encontrado"

            # ----- UI -----
            st.success("‚úÖ Conte√∫do extra√≠do com sucesso!")
            st.subheader("T√≠tulo")
            st.code(title, language=None)
            st.subheader("Texto")
            st.code(text, language=None)
            st.caption("Clique no √≠cone de c√≥pia (üìã) no canto superior direito dos blocos para copiar.")

# ----------------------------
# Como rodar localmente
# ----------------------------
# 1. pip install streamlit trafilatura[all] requests readability-lxml beautifulsoup4
# 2. streamlit run trafilatura_streamlit_app.py
